{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":96164,"databundleVersionId":12993472,"sourceType":"competition"},{"sourceId":247649840,"sourceType":"kernelVersion"}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-24T14:22:41.283644Z","iopub.execute_input":"2025-07-24T14:22:41.287045Z","iopub.status.idle":"2025-07-24T14:22:42.669642Z","shell.execute_reply.started":"2025-07-24T14:22:41.286923Z","shell.execute_reply":"2025-07-24T14:22:42.668608Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/drw-crypto-market-prediction/sample_submission.csv\n/kaggle/input/drw-crypto-market-prediction/train.parquet\n/kaggle/input/drw-crypto-market-prediction/test.parquet\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\n\ntrain = pd.read_parquet('/kaggle/input/drw-crypto-market-prediction/train.parquet')\ntrain.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T14:23:05.655595Z","iopub.execute_input":"2025-07-24T14:23:05.656300Z","iopub.status.idle":"2025-07-24T14:23:36.912214Z","shell.execute_reply.started":"2025-07-24T14:23:05.656263Z","shell.execute_reply":"2025-07-24T14:23:36.911009Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"                     bid_qty  ask_qty  buy_qty  sell_qty   volume        X1  \\\n2023-03-01 00:00:00   15.283    8.425  176.405    44.984  221.389  0.181844   \n2023-03-01 00:01:00   38.590    2.336  525.846   321.950  847.796  0.489497   \n2023-03-01 00:02:00    0.442   60.250  159.227   136.369  295.596  0.260121   \n2023-03-01 00:03:00    4.865   21.016  335.742   124.963  460.705  0.099976   \n2023-03-01 00:04:00   27.158    3.451   98.411    44.407  142.818  0.270893   \n\n                           X2        X3        X4        X5  ...      X772  \\\n2023-03-01 00:00:00 -0.637860  0.006652  0.136870  0.116698  ...  0.333753   \n2023-03-01 00:01:00 -0.075619  0.431594  0.522400  0.475255  ...  0.333657   \n2023-03-01 00:02:00 -0.444684  0.100695  0.224729  0.203282  ...  0.333667   \n2023-03-01 00:03:00 -0.666728 -0.123858  0.019197  0.014459  ...  0.333174   \n2023-03-01 00:04:00 -0.325973  0.116336  0.234311  0.214073  ...  0.333171   \n\n                         X773      X774      X775      X776      X777  \\\n2023-03-01 00:00:00 -0.009992 -0.695595 -0.444077 -0.191238 -0.184251   \n2023-03-01 00:01:00 -0.010040 -0.696226 -0.452866 -0.200082 -0.188929   \n2023-03-01 00:02:00 -0.010037 -0.696832 -0.461383 -0.208786 -0.193571   \n2023-03-01 00:03:00 -0.010279 -0.697391 -0.469628 -0.217350 -0.198175   \n2023-03-01 00:04:00 -0.010283 -0.697940 -0.477622 -0.225780 -0.202745   \n\n                         X778      X779      X780     label  \n2023-03-01 00:00:00 -0.471897 -0.625428 -0.553991  0.562539  \n2023-03-01 00:01:00 -0.472842 -0.625832 -0.554426  0.533686  \n2023-03-01 00:02:00 -0.473785 -0.626236 -0.554860  0.546505  \n2023-03-01 00:03:00 -0.474726 -0.626639 -0.555294  0.357703  \n2023-03-01 00:04:00 -0.475666 -0.627043 -0.555728  0.362452  \n\n[5 rows x 786 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bid_qty</th>\n      <th>ask_qty</th>\n      <th>buy_qty</th>\n      <th>sell_qty</th>\n      <th>volume</th>\n      <th>X1</th>\n      <th>X2</th>\n      <th>X3</th>\n      <th>X4</th>\n      <th>X5</th>\n      <th>...</th>\n      <th>X772</th>\n      <th>X773</th>\n      <th>X774</th>\n      <th>X775</th>\n      <th>X776</th>\n      <th>X777</th>\n      <th>X778</th>\n      <th>X779</th>\n      <th>X780</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2023-03-01 00:00:00</th>\n      <td>15.283</td>\n      <td>8.425</td>\n      <td>176.405</td>\n      <td>44.984</td>\n      <td>221.389</td>\n      <td>0.181844</td>\n      <td>-0.637860</td>\n      <td>0.006652</td>\n      <td>0.136870</td>\n      <td>0.116698</td>\n      <td>...</td>\n      <td>0.333753</td>\n      <td>-0.009992</td>\n      <td>-0.695595</td>\n      <td>-0.444077</td>\n      <td>-0.191238</td>\n      <td>-0.184251</td>\n      <td>-0.471897</td>\n      <td>-0.625428</td>\n      <td>-0.553991</td>\n      <td>0.562539</td>\n    </tr>\n    <tr>\n      <th>2023-03-01 00:01:00</th>\n      <td>38.590</td>\n      <td>2.336</td>\n      <td>525.846</td>\n      <td>321.950</td>\n      <td>847.796</td>\n      <td>0.489497</td>\n      <td>-0.075619</td>\n      <td>0.431594</td>\n      <td>0.522400</td>\n      <td>0.475255</td>\n      <td>...</td>\n      <td>0.333657</td>\n      <td>-0.010040</td>\n      <td>-0.696226</td>\n      <td>-0.452866</td>\n      <td>-0.200082</td>\n      <td>-0.188929</td>\n      <td>-0.472842</td>\n      <td>-0.625832</td>\n      <td>-0.554426</td>\n      <td>0.533686</td>\n    </tr>\n    <tr>\n      <th>2023-03-01 00:02:00</th>\n      <td>0.442</td>\n      <td>60.250</td>\n      <td>159.227</td>\n      <td>136.369</td>\n      <td>295.596</td>\n      <td>0.260121</td>\n      <td>-0.444684</td>\n      <td>0.100695</td>\n      <td>0.224729</td>\n      <td>0.203282</td>\n      <td>...</td>\n      <td>0.333667</td>\n      <td>-0.010037</td>\n      <td>-0.696832</td>\n      <td>-0.461383</td>\n      <td>-0.208786</td>\n      <td>-0.193571</td>\n      <td>-0.473785</td>\n      <td>-0.626236</td>\n      <td>-0.554860</td>\n      <td>0.546505</td>\n    </tr>\n    <tr>\n      <th>2023-03-01 00:03:00</th>\n      <td>4.865</td>\n      <td>21.016</td>\n      <td>335.742</td>\n      <td>124.963</td>\n      <td>460.705</td>\n      <td>0.099976</td>\n      <td>-0.666728</td>\n      <td>-0.123858</td>\n      <td>0.019197</td>\n      <td>0.014459</td>\n      <td>...</td>\n      <td>0.333174</td>\n      <td>-0.010279</td>\n      <td>-0.697391</td>\n      <td>-0.469628</td>\n      <td>-0.217350</td>\n      <td>-0.198175</td>\n      <td>-0.474726</td>\n      <td>-0.626639</td>\n      <td>-0.555294</td>\n      <td>0.357703</td>\n    </tr>\n    <tr>\n      <th>2023-03-01 00:04:00</th>\n      <td>27.158</td>\n      <td>3.451</td>\n      <td>98.411</td>\n      <td>44.407</td>\n      <td>142.818</td>\n      <td>0.270893</td>\n      <td>-0.325973</td>\n      <td>0.116336</td>\n      <td>0.234311</td>\n      <td>0.214073</td>\n      <td>...</td>\n      <td>0.333171</td>\n      <td>-0.010283</td>\n      <td>-0.697940</td>\n      <td>-0.477622</td>\n      <td>-0.225780</td>\n      <td>-0.202745</td>\n      <td>-0.475666</td>\n      <td>-0.627043</td>\n      <td>-0.555728</td>\n      <td>0.362452</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 786 columns</p>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import Ridge, BayesianRidge\nimport xgboost as xgb\nimport lightgbm as lgb\nimport gc\n\nSEED = 2024\nnp.random.seed(SEED)\n\n# Load\nprint(\"📦 Loading Data...\")\ntrain = pd.read_parquet('/kaggle/input/drw-crypto-market-prediction/train.parquet')\ntest = pd.read_parquet('/kaggle/input/drw-crypto-market-prediction/test.parquet')\nsample_submission = pd.read_csv('/kaggle/input/drw-crypto-market-prediction/sample_submission.csv')\n\n# Feature Engineering\ndef engineer_features(df):\n    df = df.copy()\n    df['spread'] = np.abs(df['ask_qty'] - df['bid_qty']) / (df['ask_qty'] + df['bid_qty'] + 1e-6)\n    df['ofi'] = (df['bid_qty'] - df['ask_qty']) / (df['bid_qty'] + df['ask_qty'] + 1e-6)\n    df['buy_sell_ratio'] = (df['buy_qty'] + 1e-6) / (df['sell_qty'] + 1e-6)\n    df['volume_imbalance'] = (df['buy_qty'] - df['sell_qty']) / (df['buy_qty'] + df['sell_qty'] + 1e-6)\n    df['log_volume'] = np.log1p(df['volume'])\n    df['liquidity_imbalance'] = (df['bid_qty'] - df['ask_qty']) / (df['bid_qty'] + df['ask_qty'] + 1e-6)\n    df.replace([np.inf, -np.inf], 0, inplace=True)\n    df.fillna(0, inplace=True)\n    return df.astype(np.float32)\n\ndef add_simple_rolling(df, features, windows=[3, 5], lags=[1]):\n    df_new = df.copy()\n    for col in features:\n        for w in windows:\n            df_new[f'{col}_rollmean{w}'] = df[col].rolling(window=w, min_periods=1).mean()\n            df_new[f'{col}_ema{w}'] = df[col].ewm(span=w, adjust=False).mean()\n        for l in lags:\n            df_new[f'{col}_lag{l}'] = df[col].shift(l)\n    df_new.replace([np.inf, -np.inf], 0, inplace=True)\n    df_new.fillna(0, inplace=True)\n    return df_new.astype(np.float32)\n\nprint(\"🛠 Feature Engineering...\")\ntrain = engineer_features(train)\ntest = engineer_features(test)\n\ncore_feats = ['spread', 'ofi', 'buy_sell_ratio', 'volume_imbalance', 'liquidity_imbalance', 'log_volume']\nprint(f\"Using core features: {core_feats}\")\n\ntrain = add_simple_rolling(train, core_feats)\ntest = add_simple_rolling(test, core_feats)\n\nignore = set(['timestamp', 'asset', 'label', 'log_return_forward_1s'])\nfeature_cols = [col for col in train.columns if col not in ignore and not train[col].isnull().all()]\n\nmin_lag = 5\ntrain = train.iloc[min_lag:].reset_index(drop=True)\n\n# Scaling\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(train[feature_cols])\nX_test_scaled = scaler.transform(test[feature_cols])\n\ny_raw = train['label']\ny = (y_raw - y_raw.mean()) / (y_raw.std() + 1e-6)\n\n# Time-based Split\nN = len(X_train_scaled)\nsplit = int(0.85 * N)\ngap = int(0.05 * N)\nX_tr = X_train_scaled[:split]\ny_tr = y.iloc[:split]\nX_val = X_train_scaled[split + gap:]\ny_val = y.iloc[split + gap:]\n\ndel train\ngc.collect()\n\nprint(\"🎯 Training Models...\")\n\n# XGBoost\nmodel_xgb = xgb.XGBRegressor(\n    objective='reg:squarederror',\n    learning_rate=0.012,\n    max_depth=5,\n    n_estimators=500,\n    subsample=0.85,\n    colsample_bytree=0.7,\n    tree_method='hist',\n    reg_alpha=0.4,\n    reg_lambda=1.5,\n    early_stopping_rounds=30,\n    random_state=SEED,\n    verbosity=0\n)\nmodel_xgb.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], verbose=False)\nxgb_val = model_xgb.predict(X_val)\n\n# LightGBM\nmodel_lgb = lgb.LGBMRegressor(\n    objective='regression',\n    learning_rate=0.01,\n    max_depth=6,\n    n_estimators=500,\n    subsample=0.85,\n    colsample_bytree=0.75,\n    reg_alpha=0.3,\n    reg_lambda=1.2,\n    max_bin=96,\n    force_col_wise=True,\n    random_state=SEED\n)\nmodel_lgb.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], eval_metric='rmse')\nlgb_val = model_lgb.predict(X_val)\n\n# Ridge\nridge = Ridge(alpha=1.0)\nridge.fit(X_tr, y_tr)\nridge_val = ridge.predict(X_val)\n\n# Bayesian Ridge\nbayes = BayesianRidge()\nbayes.fit(X_tr, y_tr)\nbayes_val = bayes.predict(X_val)\n\n# Blend\nw_xgb = 0.45\nw_lgb = 0.3\nw_ridge = 0.15\nw_bayes = 0.10\n\nval_blend = w_xgb * xgb_val + w_lgb * lgb_val + w_ridge * ridge_val + w_bayes * bayes_val\nval_corr = np.corrcoef(y_val, val_blend)[0, 1]\nprint(\"📈 Validation Pearson Correlation (blended):\", round(val_corr, 6))\n\ndel X_tr, X_val, y_tr, y_val\ngc.collect()\n\nprint(\"✏️ Predicting on Test Set...\")\nxgb_pred = model_xgb.predict(X_test_scaled)\nlgb_pred = model_lgb.predict(X_test_scaled)\nridge_pred = ridge.predict(X_test_scaled)\nbayes_pred = bayes.predict(X_test_scaled)\n\ntest_preds = w_xgb * xgb_pred + w_lgb * lgb_pred + w_ridge * ridge_pred + w_bayes * bayes_pred\ntest_preds_final = test_preds * y_raw.std() + y_raw.mean()\n\nprint(\"💾 Saving Submission...\")\nsubmission = sample_submission.copy()\nsubmission['prediction'] = test_preds_final\nsubmission.to_csv('submission.csv', index=False)\nprint(\"✅ submission.csv saved with\", len(submission), \"rows.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-25T03:48:59.058500Z","iopub.execute_input":"2025-07-25T03:48:59.059119Z","iopub.status.idle":"2025-07-25T03:59:56.867237Z","shell.execute_reply.started":"2025-07-25T03:48:59.059078Z","shell.execute_reply":"2025-07-25T03:59:56.865939Z"}},"outputs":[{"name":"stdout","text":"📦 Loading Data...\n🛠 Feature Engineering...\nUsing core features: ['spread', 'ofi', 'buy_sell_ratio', 'volume_imbalance', 'liquidity_imbalance', 'log_volume']\n🎯 Training Models...\n[LightGBM] [Info] Total Bins 78804\n[LightGBM] [Info] Number of data points in the train set: 446998, number of used features: 821\n[LightGBM] [Info] Start training from score -0.009776\n📈 Validation Pearson Correlation (blended): 0.065957\n✏️ Predicting on Test Set...\n💾 Saving Submission...\n✅ submission.csv saved with 538150 rows.\n","output_type":"stream"}],"execution_count":1}]}